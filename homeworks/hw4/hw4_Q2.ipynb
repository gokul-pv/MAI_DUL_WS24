{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "87ce1c2d",
      "metadata": {
        "id": "87ce1c2d"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "## General Tips\n",
        "In each homework problem, you will implement and train various diffusion models.\n",
        "\n",
        "Feel free to print whatever output (e.g. debugging code, training code, etc) you want, as the graded submission will be the submitted pdf with images.\n",
        "\n",
        "After you complete the assignment, download all of the images outputted in the results/ folder and upload them to the figure folder in the given latex template.\n",
        "\n",
        "Run the cells below to download and load up the starter code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7d20590",
      "metadata": {
        "id": "d7d20590"
      },
      "outputs": [],
      "source": [
        "# magic for autoreloading of modules\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# get to the parent dir of mai_dul repo\n",
        "import os\n",
        "os.chdir('../../')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "393ef0e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# install latest version deepul package\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f55a3dd",
      "metadata": {
        "id": "3f55a3dd"
      },
      "outputs": [],
      "source": [
        "from deepul.hw4_helper import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8fcc41",
      "metadata": {
        "id": "fc8fcc41"
      },
      "source": [
        "# Question 2: Pixel-Space Diffusion on CIFAR-10 [30pt]\n",
        "\n",
        "In this question, we will train pixel-space UNet diffusion model on CIFAR-10\n",
        "\n",
        "Execute the cell below to visualize our datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44f9d642",
      "metadata": {
        "id": "44f9d642"
      },
      "outputs": [],
      "source": [
        "visualize_q2_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "370c91ef",
      "metadata": {
        "id": "370c91ef"
      },
      "source": [
        "We'll use a UNet architecture similar to the original [DDPM](https://arxiv.org/abs/2006.11239) paper. We provide the following pseudocode for each part of the model:\n",
        "```\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = np.exp(-np.log(max_period) * np.arange(0, half, dtype=float32) / half)\n",
        "    args = timesteps[:, None].astype(float32) * freqs[None]\n",
        "    embedding = cat([np.cos(args), np.sin(args)], axis=-1)\n",
        "    if dim % 2:\n",
        "        embedding = cat([embedding, np.zeros_like(embedding[:, :1])], axis=-1)\n",
        "    return embedding\n",
        "\n",
        "ResidualBlock(in_channels, out_channels, temb_channels)\n",
        "    Given x, temb\n",
        "    h = Conv2d(in_channels, out_channels, 3, padding=1)(x)\n",
        "    h = GroupNorm(num_groups=8, num_channels=out_channels)(h)\n",
        "    h = SiLU()(h)\n",
        "    \n",
        "    temb = Linear(temb_channels, out_channels)(temb)\n",
        "    h += temb[:, :, None, None] # h is BxDxHxW, temb is BxDx1x1\n",
        "    \n",
        "    h = Conv2d(out_channels, out_channels, 3, padding=1)(h)\n",
        "    h = GroupNorm(num_groups=8, num_channels=out_channels)(h)\n",
        "    h = SiLU()(h)\n",
        "    \n",
        "    if in_channels != out_channels:\n",
        "        x = Conv2d(in_channels, out_channels, 1)(x)\n",
        "    return x + h\n",
        "    \n",
        "Downsample(in_channels)\n",
        "    Given x\n",
        "    return Conv2d(in_channels, in_channels, 3, stride=2, padding=1)(x)\n",
        "\n",
        "Upsample(in_channels)\n",
        "    Given x\n",
        "    x = interpolate(x, scale_factor=2)\n",
        "    x = Conv2d(in_channels, in_channels, 3, padding=1)(x)\n",
        "    return x\n",
        "    \n",
        "UNet(in_channels, hidden_dims, blocks_per_dim)\n",
        "    Given x, t\n",
        "    temb_channels = hidden_dims[0] * 4\n",
        "    emb = timestep_embedding(t, hidden_dims[0])\n",
        "    emb = Sequential(Linear(hidden_dims[0], temb_channels), SiLU(), Linear(temb_channels, temb_channels))(emb)\n",
        "    \n",
        "    h = Conv2d(in_channels, hidden_dims[0], 3, padding=1)(x)\n",
        "    hs = [h]\n",
        "    prev_ch = hidden_dims[0]\n",
        "    down_block_chans = [prev_ch]\n",
        "    for i, hidden_dim in enumerate(hidden_dims):\n",
        "        for _ in range(blocks_per_dim):\n",
        "            h = ResidualBlock(prev_ch, hidden_dim, temb_channels)(h, emb)\n",
        "            hs.append(h)\n",
        "            prev_ch = hidden_dim\n",
        "            down_block_chans.append(prev_ch)\n",
        "        if i != len(hidden_dims) - 1:\n",
        "            h = Downsample(prev_ch)(h)\n",
        "            hs.append(h)\n",
        "            down_block_chans.append(prev_ch)\n",
        "    \n",
        "    h = ResidualBlock(prev_ch, prev_ch, temb_channels)(h, emb)\n",
        "    h = ResidualBlock(prev_ch, prev_ch, temb_channels)(h, emb)\n",
        "    \n",
        "    for i, hidden_dim in list(enumerate(hidden_dims))[::-1]:\n",
        "        for j in range(blocks_per_dim + 1):\n",
        "            dch = down_block_chans.pop()\n",
        "            h = ResidualBlock(prev_ch + dch, hidden_dim, temb_channels)(cat(h, hs.pop()), emb)\n",
        "            prev_ch = hidden_dim\n",
        "            if i and j == blocks_per_dim:\n",
        "                h = Upsample(prev_ch)(h)\n",
        "    \n",
        "    h = GroupNorm(num_groups=8, num_channels=prev_ch)(h)\n",
        "    h = SiLU()(h)\n",
        "    out = Conv2d(prev_ch, in_channels, 3, padding=1)(h)\n",
        "    return out\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff725c4",
      "metadata": {
        "id": "7ff725c4"
      },
      "source": [
        "**Hyperparameter details**\n",
        "* Normalize data to [-1, 1]\n",
        "* UNET with hidden_dims as [64, 128, 256, 512] and 2 blocks_per_dim\n",
        "* Train 60 epochs, batch size 256, Adam with LR 1e-3 (100 warmup steps, cosine decay to 0)\n",
        "* For diffusion schedule, sampling and loss, use the same setup as Q1\n",
        "\n",
        "You may also find it helpful to clip $\\hat{x} = \\frac{x_t - \\sigma_t \\hat{\\epsilon}}{\\alpha_t}$ to [-1, 1] during each sampling step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d7cb9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from homeworks.hw4.model import UNet\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b39b28",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_scheduler(optimizer, warmup_steps=100, max_steps=None):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        progress = float(current_step - warmup_steps) / float(max(1, max_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    \n",
        "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50790669",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_noise_schedule(t):\n",
        "    \"\"\"Compute alpha_t and sigma_t using cosine schedule\"\"\"\n",
        "    alpha_t = torch.cos(math.pi * t / 2)\n",
        "    sigma_t = torch.sin(math.pi * t / 2)\n",
        "    return alpha_t, sigma_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3126343",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ddpm_update(x, eps_hat, t, t_prev):\n",
        "    \"\"\"Perform single DDPM update step\"\"\"\n",
        "    alpha_t, sigma_t = get_noise_schedule(t)\n",
        "    alpha_prev, sigma_prev = get_noise_schedule(t_prev)\n",
        "    \n",
        "    # Compute eta_t according to DDPM formula\n",
        "    eta_t = (sigma_prev / sigma_t) * torch.sqrt(1 - (alpha_t**2 / alpha_prev**2))\n",
        "    \n",
        "    # Compute predicted x0 (clipped to [-1, 1])\n",
        "    x0_pred = torch.clamp((x - sigma_t * eps_hat) / alpha_t, -1, 1)\n",
        "    \n",
        "    # Compute variance term (clip to avoid numerical issues)\n",
        "    var_term = torch.clamp(sigma_prev**2 - eta_t**2, min=0)\n",
        "    \n",
        "    # Sample noise\n",
        "    epsilon = torch.randn_like(x)\n",
        "    \n",
        "    # Compute next x\n",
        "    x_prev = alpha_prev * x0_pred + torch.sqrt(var_term) * eps_hat + eta_t * epsilon\n",
        "    \n",
        "    return x_prev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e17703",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_diffusion(model, num_samples, num_steps, img_size=32, device='cuda'):\n",
        "    \"\"\"Sample from the diffusion model using DDPM\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Initialize from normal distribution\n",
        "    x = torch.randn(num_samples, 3, img_size, img_size).to(device)\n",
        "    \n",
        "    # Create timesteps\n",
        "    ts = torch.linspace(1 - 1e-4, 1e-4, num_steps + 1).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(num_steps):\n",
        "            t = ts[i]\n",
        "            t_prev = ts[i + 1]\n",
        "            \n",
        "            # Get noise prediction\n",
        "            eps_hat = model(x, t.expand(num_samples))\n",
        "            \n",
        "            # Update x\n",
        "            x = ddpm_update(x, eps_hat, t, t_prev)\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb26d1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, optimizer, scheduler, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    pbar = tqdm(train_loader, unit='batch')\n",
        "    \n",
        "    for batch_id, batch in enumerate(pbar):\n",
        "        x = batch[0].to(device)\n",
        "        \n",
        "        # Sample t and noise\n",
        "        t = torch.rand(x.size(0)).to(device)\n",
        "        epsilon = torch.randn_like(x)\n",
        "        \n",
        "        # Forward process\n",
        "        alpha_t, sigma_t = get_noise_schedule(t)\n",
        "        alpha_t = alpha_t.view(-1, 1, 1, 1)\n",
        "        sigma_t = sigma_t.view(-1, 1, 1, 1)\n",
        "        x_t = alpha_t * x + sigma_t * epsilon\n",
        "        \n",
        "        # Predict noise\n",
        "        epsilon_pred = model(x_t, t)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = torch.mean((epsilon - epsilon_pred) ** 2)\n",
        "        \n",
        "        # Optimization step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        pbar.set_description(desc=f\"Batch loss={loss:.4f}\")\n",
        "        # break\n",
        "    \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a278b73",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_loss(model, loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate model loss on given data loader.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch[0].to(device)\n",
        "            \n",
        "            # Sample t and noise\n",
        "            t = torch.rand(x.size(0)).to(device)\n",
        "            epsilon = torch.randn_like(x)\n",
        "            \n",
        "            # Forward process\n",
        "            alpha_t, sigma_t = get_noise_schedule(t)\n",
        "            alpha_t = alpha_t.view(-1, 1, 1, 1)\n",
        "            sigma_t = sigma_t.view(-1, 1, 1, 1)\n",
        "            x_t = alpha_t * x + sigma_t * epsilon\n",
        "            \n",
        "            # Predict noise\n",
        "            epsilon_pred = model(x_t, t)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = torch.mean((epsilon - epsilon_pred) ** 2)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # break\n",
        "    \n",
        "    return total_loss / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f2f342",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_samples(model, num_samples_per_row=10, device='cuda'):\n",
        "    \"\"\"\n",
        "    Generate samples from the trained model with different numbers of steps.\n",
        "    \"\"\"\n",
        "    step_range = np.power(2, np.linspace(0, 9, 10)).astype(int)\n",
        "    samples = []\n",
        "    \n",
        "    for num_steps in step_range:\n",
        "        row_samples = sample_diffusion(model, num_samples_per_row, num_steps, device=device)\n",
        "        # Transform from [-1, 1] to [0, 1]\n",
        "        row_samples = (row_samples + 1) / 2\n",
        "        row_samples = torch.clamp(row_samples, 0, 1)\n",
        "        row_samples = row_samples.permute(0, 2, 3, 1)\n",
        "        samples.append(row_samples)\n",
        "        # break\n",
        "    \n",
        "    samples = torch.stack(samples).cpu().numpy()\n",
        "\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e99958",
      "metadata": {},
      "outputs": [],
      "source": [
        "def q2(train_data, test_data):\n",
        "    \"\"\"\n",
        "    train_data: A (50000, 32, 32, 3) numpy array of images in [0, 1]\n",
        "    test_data: A (10000, 32, 32, 3) numpy array of images in [0, 1]\n",
        "\n",
        "    Returns\n",
        "    - a (# of training iterations,) numpy array of train losses evaluated every minibatch\n",
        "    - a (# of num_epochs + 1,) numpy array of test losses evaluated at the start of training and the end of every epoch\n",
        "    - a numpy array of size (10, 10, 32, 32, 3) of samples in [0, 1] drawn from your model.\n",
        "      The array represents a 10 x 10 grid of generated samples. Each row represents 10 samples generated\n",
        "      for a specific number of diffusion timesteps. Do this for 10 evenly logarithmically spaced integers\n",
        "      1 to 512, i.e. np.power(2, np.linspace(0, 9, 10)).astype(int)\n",
        "    \"\"\"\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                         else \"mps\" if torch.backends.mps.is_available() \n",
        "                         else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # DataLoader settings based on device\n",
        "    kwargs = {'num_workers': 8, 'pin_memory': True} if torch.cuda.is_available() else \\\n",
        "            {'num_workers': 8} if torch.backends.mps.is_available() else \\\n",
        "            {}\n",
        "    \n",
        "    # Hyperparameters\n",
        "    hidden_dim = [64, 128, 256, 512]\n",
        "    num_epochs = 30\n",
        "    batch_size = 256\n",
        "    learning_rate = 1e-3\n",
        "\n",
        "    # Normalize data to [-1, 1]\n",
        "    train_data = train_data * 2 - 1\n",
        "    test_data = test_data * 2 - 1\n",
        "    \n",
        "    # Convert to PyTorch tensors\n",
        "    train_tensor = torch.FloatTensor(train_data).permute(0, 3, 1, 2)\n",
        "    test_tensor = torch.FloatTensor(test_data).permute(0, 3, 1, 2)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = TensorDataset(train_tensor)\n",
        "    test_dataset = TensorDataset(test_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, **kwargs)\n",
        "    \n",
        "    # Initialize model and optimizer\n",
        "    model = UNet(in_channels=3, hidden_dims=hidden_dim, blocks_per_dim=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Setup scheduler\n",
        "    total_steps = len(train_loader) * num_epochs\n",
        "    scheduler = get_scheduler(optimizer, warmup_steps=100, max_steps=total_steps)\n",
        "\n",
        "    \n",
        "    # Training\n",
        "    train_losses = []\n",
        "    test_losses = [evaluate_loss(model, test_loader, device)]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        \n",
        "        # Train one epoch\n",
        "        epoch_losses = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
        "        train_losses.extend(epoch_losses)\n",
        "        \n",
        "        # Evaluate test loss\n",
        "        test_loss = evaluate_loss(model, test_loader, device)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        # break\n",
        "\n",
        "    # Generate samples\n",
        "    samples = generate_samples(model, num_samples_per_row=10, device=device)\n",
        "\n",
        "    return np.array(train_losses), np.array(test_losses), samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ea5a82",
      "metadata": {
        "id": "76ea5a82"
      },
      "outputs": [],
      "source": [
        "q2_save_results(q2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
